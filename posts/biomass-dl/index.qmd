---
title: "Above Ground Biomass Estimation with Deep Learniing"
author: "Najah"
date: "2024-05-20"
description: ""
image: dl_cover.png
filters:
   - lightbox
lightbox: 
  match: auto
toc: false
toc-depth: 5

code-fold: true
categories: 
execute: 
  eval: false
---



I’ve been working on the problem of biomass estimation in India. It’s a complex challenge for a few reasons:

-	Lack of high-quality, high-resolution training data
-	Difficulty in mapping without LiDAR support
-	Complex, nonlinear relationships between biomass and input features
-	Saturation of biomass estimates beyond 350 Mg/ha

We initially worked with NASA’s GEDI data. However, it consistently underestimated values for the specific geographies I was working on. The resolution and forest structure in India likely didn’t align well with GEDI’s assumptions.

Eventually, we found a more reliable dataset: above-ground biomass (AGB) maps generated by ISRO using airborne LiDAR and field plots. This dataset was of significantly higher quality, and we decided to move forward with it. We had five field sites across India to work with.

**Input Data and Early Models**

There were many combinations to try—different sensors, resolutions, temporal layers, and derived features. I’ll cover those explorations in detail in a future post.

We focused primarily on:

-	Optical imagery: Sentinel-2, Landsat 8
-	Radar data: Sentinel-1 (dual-pol), PALSAR
-	Temporal layers: Three seasonal composites (pre-monsoon, monsoon, post-monsoon)
-	Dimensionality reduction: PCA, yielding 99 input features

The first approach used basic machine learning models (Random Forest, XGBoost) on tabular features extracted from the raster stack. The accuracy plateaued around 60–70% (R²), with RMSE often exceeding 50 Mg/ha.

**Patchwise Deep Learning**

To introduce spatial awareness, I moved to patch-based modeling. This worked better. I trained models like ResNet and Fully Convolutional Networks (FCNs) on 16×16 pixel patches. Performance improved significantly—R² reached above 85%, and RMSE dropped to around 35 Mg/ha. But the outputs were still patch-level, and sliding-window inference blurred the spatial detail.

**Towards Pixelwise Predictions**

That led me to redesign the workflow for pixelwise modeling. After many iterations and simplifications, I settled on a ResNet-style convolutional regression model that predicts directly at the pixel level.

To add spatial context (and avoid the pitfalls of purely pixel-based CNNs), I introduced several enhancements:

-	Surrounding context as multi-channel inputs
-	Multi-season temporal composites
-	Spatially smoothed biomass targets to aid learning
-	Experimental use of attention bottlenecks (still under testing)

With this pixelwise approach, we now reach R² ≈ 0.9, RMSE < 30 Mg/ha, and MAE < 20 Mg/ha—which is on par or better than what I’ve seen in several peer-reviewed studies.

**Model Access & What’s Next**

I’m still finalizing documentation, but the code and models are now public:

- Training code: https://github.com/vertify-earth/biomass-dl-model-training
-	Inference pipeline: https://github.com/vertify-earth/biomass-dl-model-training/blob/main/biomass_inference_notebook_Version2.ipynb
-	Model hub: https://huggingface.co/vertify/biomass-model
-	Live demo: https://vertify-biomass-prediction-app.hf.space/

I’ll write a more detailed post later covering all the experiments, failed directions, and lessons learned.

Thanks for reading.

